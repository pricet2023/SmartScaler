{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6c9754b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import docker\n",
    "import docker.errors\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfc751a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Training Data (Images must be build first, see Makefile)\n",
    "client = docker.from_env()\n",
    "\n",
    "def run_container(image, container_name, duration=200, interval=1):\n",
    "    container = client.containers.run(\n",
    "        image, \n",
    "        name=container_name,\n",
    "        detach=True,\n",
    "        auto_remove=True,\n",
    "        cpu_period=100000,\n",
    "        cpu_quota=50000,\n",
    "    )\n",
    "\n",
    "    container = client.containers.get(container_name)\n",
    "    stats = []\n",
    "\n",
    "    stat_gen = container.stats(decode=True, stream=True)\n",
    "    for _ in range(int(duration / interval)):\n",
    "        stat = next(stat_gen)\n",
    "        cpu_stats = stat.get(\"cpu_stats\", {})\n",
    "        precpu_stats = stat.get(\"precpu_stats\", {})\n",
    "        cpu_delta = cpu_stats.get(\"cpu_usage\", {}).get(\"total_usage\", 0) - precpu_stats.get(\"cpu_usage\", {}).get(\"total_usage\", 0)\n",
    "        system_cpu_delta = cpu_stats.get(\"system_cpu_usage\", 0) - precpu_stats.get(\"system_cpu_usage\", 0)\n",
    "        cpu_percent = (cpu_delta / system_cpu_delta) * len(cpu_stats.get(\"cpu_usage\", {}).get(\"percpu_usage\", [])) * 100 if system_cpu_delta else 0.0\n",
    "\n",
    "        stats.append(cpu_percent)\n",
    "        print(f\"{container_name}: CPU {cpu_percent}%\")\n",
    "        time.sleep(interval)\n",
    "    \n",
    "    container.kill()\n",
    "    return stats\n",
    "\n",
    "def collect_sequential_stats(image_list, duration=200):\n",
    "    data = {}\n",
    "    for i, image in enumerate(image_list):\n",
    "        container_name = f\"container_{i}\"\n",
    "        cpu_data = run_container(image, container_name, duration=duration)\n",
    "        data[container_name] = cpu_data\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def aggregate(df):\n",
    "    df['mean_cpu'] = df.mean(axis=1)\n",
    "    df['max_cpu'] = df.max(axis=1)\n",
    "    return df[['mean_cpu', 'max_cpu']]\n",
    "\n",
    "def create_sliding_windows(df_agg, window_size=50):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for i in range(len(df_agg) - window_size):\n",
    "        seq = df_agg.iloc[i:i+window_size].values  # shape (50, 2)\n",
    "        target = df_agg.iloc[i+window_size].values  # predict next step (mean_cpu, max_cpu)\n",
    "        sequences.append(seq)\n",
    "        targets.append(target)\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "\n",
    "def generate_cpu_dataset(num_containers=5, duration_per_run=200, no_runs=10, window_size=50):\n",
    "    all_sequences = []\n",
    "    all_targets = []\n",
    "    image_names = [\"cpu_max\", \"periodic_cpu_spikes\", \"random_cpu\"]\n",
    "    for run_idx in range(no_runs):\n",
    "        print(f\"\\n=== Generating sample {run_idx + 1}/{no_runs} ===\")\n",
    "        rand_image_set = [random.choice(image_names) for _ in range(num_containers)]\n",
    "\n",
    "        df_raw = collect_sequential_stats(rand_image_set, duration_per_run)\n",
    "        df_agg = aggregate(df_raw)\n",
    "\n",
    "        seqs, targets = create_sliding_windows(df_agg, window_size=window_size)\n",
    "\n",
    "        all_sequences.append(seqs)\n",
    "        all_targets.append(targets)\n",
    "\n",
    "    X = np.concatenate(all_sequences, axis=0)\n",
    "    y = np.concatenate(all_targets, axis=0)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X, y = generate_cpu_dataset(num_containers=1, duration_per_run=30, no_runs=5, window_size=10)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X, y, test_size=0.5, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30f911e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10, 2)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "609c1905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1/50, Train Loss: 1442.9646, Val Loss: 1337.1406\n",
      "Epoch 2/50, Train Loss: 1438.7935, Val Loss: 1382.7479\n",
      "Epoch 3/50, Train Loss: 1350.3973, Val Loss: 1374.4821\n",
      "Epoch 4/50, Train Loss: 1295.0834, Val Loss: 1365.8193\n",
      "Epoch 5/50, Train Loss: 1363.6473, Val Loss: 1339.4604\n",
      "Epoch 6/50, Train Loss: 1358.0842, Val Loss: 1254.1259\n",
      "Epoch 7/50, Train Loss: 1319.7946, Val Loss: 1268.2215\n",
      "Epoch 8/50, Train Loss: 1217.0345, Val Loss: 1238.9847\n",
      "Epoch 9/50, Train Loss: 1196.2984, Val Loss: 1237.6154\n",
      "Epoch 10/50, Train Loss: 1222.5677, Val Loss: 1187.6682\n",
      "Epoch 11/50, Train Loss: 1165.8196, Val Loss: 1175.0207\n",
      "Epoch 12/50, Train Loss: 1212.9906, Val Loss: 1160.5990\n",
      "Epoch 13/50, Train Loss: 1158.2549, Val Loss: 1143.1648\n",
      "Epoch 14/50, Train Loss: 1152.2730, Val Loss: 1100.0191\n",
      "Epoch 15/50, Train Loss: 1065.5382, Val Loss: 1122.1763\n",
      "Epoch 16/50, Train Loss: 1101.8694, Val Loss: 1114.5014\n",
      "Epoch 17/50, Train Loss: 1079.3014, Val Loss: 1087.8870\n",
      "Epoch 18/50, Train Loss: 1075.6380, Val Loss: 1056.6896\n",
      "Epoch 19/50, Train Loss: 1003.1946, Val Loss: 1052.0951\n",
      "Epoch 20/50, Train Loss: 1056.7064, Val Loss: 1023.2222\n",
      "Epoch 21/50, Train Loss: 1040.2406, Val Loss: 1006.9206\n",
      "Epoch 22/50, Train Loss: 1033.7842, Val Loss: 1011.3446\n",
      "Epoch 23/50, Train Loss: 961.9990, Val Loss: 946.5781\n",
      "Epoch 24/50, Train Loss: 958.8946, Val Loss: 987.6825\n",
      "Epoch 25/50, Train Loss: 988.5615, Val Loss: 963.6359\n",
      "Epoch 26/50, Train Loss: 922.3513, Val Loss: 908.9748\n",
      "Epoch 27/50, Train Loss: 949.9044, Val Loss: 955.6383\n",
      "Epoch 28/50, Train Loss: 961.3459, Val Loss: 891.4892\n",
      "Epoch 29/50, Train Loss: 936.9111, Val Loss: 880.0876\n",
      "Epoch 30/50, Train Loss: 904.1498, Val Loss: 877.2805\n",
      "Epoch 31/50, Train Loss: 875.8642, Val Loss: 867.2525\n",
      "Epoch 32/50, Train Loss: 864.0512, Val Loss: 883.2124\n",
      "Epoch 33/50, Train Loss: 870.5450, Val Loss: 875.2872\n",
      "Epoch 34/50, Train Loss: 859.9982, Val Loss: 830.5860\n",
      "Epoch 35/50, Train Loss: 828.8914, Val Loss: 870.3701\n",
      "Epoch 36/50, Train Loss: 811.3183, Val Loss: 845.8603\n",
      "Epoch 37/50, Train Loss: 831.5482, Val Loss: 841.4711\n",
      "Epoch 38/50, Train Loss: 822.4578, Val Loss: 788.1059\n",
      "Epoch 39/50, Train Loss: 785.2640, Val Loss: 793.9824\n",
      "Epoch 40/50, Train Loss: 802.8387, Val Loss: 757.9164\n",
      "Epoch 41/50, Train Loss: 783.7588, Val Loss: 799.9154\n",
      "Epoch 42/50, Train Loss: 765.5955, Val Loss: 792.5800\n",
      "Epoch 43/50, Train Loss: 766.4523, Val Loss: 754.2943\n",
      "Epoch 44/50, Train Loss: 780.5793, Val Loss: 748.2464\n",
      "Epoch 45/50, Train Loss: 735.6283, Val Loss: 729.0298\n",
      "Epoch 46/50, Train Loss: 714.4792, Val Loss: 736.0969\n",
      "Epoch 47/50, Train Loss: 711.7835, Val Loss: 750.4468\n",
      "Epoch 48/50, Train Loss: 740.1532, Val Loss: 704.8580\n",
      "Epoch 49/50, Train Loss: 717.9373, Val Loss: 736.4806\n",
      "Epoch 50/50, Train Loss: 705.4416, Val Loss: 681.0499\n"
     ]
    }
   ],
   "source": [
    "class CPULSTM(nn.Module):\n",
    "    def __init__(self, input_size=2, hidden_size=64, num_layers=2, output_size=2):\n",
    "        super(CPULSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len, input_size)\n",
    "        out, _ = self.lstm(x)  # out shape: (batch, seq_len, hidden_size)\n",
    "        out = out[:, -1, :]    # Take last time step's output\n",
    "        out = self.fc(out)     # Final prediction: (batch, output_size)\n",
    "        return out\n",
    "\n",
    "# Set Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create TensorDatasets from your prepared data\n",
    "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.float32))\n",
    "val_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Model, loss, optimizer\n",
    "model = CPULSTM().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# init tensorboard, (ensure it is running first)\n",
    "writer = SummaryWriter(log_dir='runs/cpu_forecast_experiment')\n",
    "\n",
    "# Training loop\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for batch_x, batch_y in train_dataloader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "         # Validation\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in val_dataloader:\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            total_val_loss += loss.item()\n",
    "    \n",
    "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "\n",
    "    # Log to TensorBoard\n",
    "    writer.add_scalar('Loss/Train', avg_train_loss, epoch)\n",
    "    writer.add_scalar('Loss/Val', avg_val_loss, epoch)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {total_train_loss / len(train_dataloader):.4f}, Val Loss: {total_val_loss / len(val_dataloader):.4f}\")\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81c8205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "\n",
    "# Evaluate performance with test data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "    preds = model(X_test_tensor)\n",
    "    preds = preds.cpu().numpy()\n",
    "    y_true = y_test_tensor.cpu().numpy()\n",
    "\n",
    "# Calculate MAE or RMSE on test set\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_true, preds))\n",
    "mae = mean_absolute_error(y_true, preds)\n",
    "print(f\"Test RMSE: {rmse:.4f}, Test MAE: {mae:.4f}\")\n",
    "\n",
    "# Plot prediction from a test sequence\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Choose one random test sequence\n",
    "sample_idx = np.random.randint(len(X_test))\n",
    "input_seq = X_test[sample_idx]  # shape (50, 2)\n",
    "true_target = y_test[sample_idx]  # shape (2, )\n",
    "predicted_target = preds[sample_idx]  # shape (2, )\n",
    "\n",
    "# Plotting the input sequence and the true vs predicted next step\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot mean_cpu sequence\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(input_seq[:, 0], label=\"Input mean_cpu (past 50s)\")\n",
    "plt.axhline(y=true_target[0], color='green', linestyle='--', label=\"True mean_cpu (next)\")\n",
    "plt.axhline(y=predicted_target[0], color='red', linestyle='--', label=\"Predicted mean_cpu (next)\")\n",
    "plt.title(\"Mean CPU usage\")\n",
    "plt.legend()\n",
    "\n",
    "# Plot max_cpu sequence\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(input_seq[:, 1], label=\"Input max_cpu (past 50s)\")\n",
    "plt.axhline(y=true_target[1], color='green', linestyle='--', label=\"True max_cpu (next)\")\n",
    "plt.axhline(y=predicted_target[1], color='red', linestyle='--', label=\"Predicted max_cpu (next)\")\n",
    "plt.title(\"Max CPU usage\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
